dataset:
    root: "/path/to/dataset"
    max_seg: 64
    max_seg_len: 64
trainer:
    lr: 0.00005
    batch_size: 32
    epochs: 100
    split: [0.90, 1.0]
    early_stopping_patience: 5
    early_stopping_mode: 'min'
model:
    tokenizer: "tk-name.json"
    t2v_scale: 1.0
    d_model: 768
    n_head: 12
    d_ff: 2048
    n_block: 3
    dropout: 0.0
    weight_tying: true
    attn_backend: "efficient_attention"
