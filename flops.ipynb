{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a59ef5-8613-4d8b-88ad-263c9b532045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f14a055-0695-4a31-8f6e-57bf3b333b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from tokenizers import Tokenizer\n",
    "from src.utils.data_utils import SeqSet, Seq, random_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a93ba4-8981-4f15-81ab-05520245a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer.from_file(\n",
    "    \"./dataset/instacart/data/tk.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb97a05-a068-48ad-b43e-7fc8b728fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import FMConfig\n",
    "from src.utils.model_utils import build_model\n",
    "from src.utils.train_utils import (\n",
    "    load_cfg,\n",
    "    build_trainer,\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48421a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_TOKENS = 2048\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553da957-0173-402a-ac07-d6afe6ab8e69",
   "metadata": {},
   "source": [
    "### bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05a202-8ace-4df9-85dd-cf77f4d7bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instacart = Seq(\n",
    "    tokenizer=tk,\n",
    "    data_root=\"./dataset/instacart/data\",\n",
    "    data_folder=\"./dataset/instacart/data/instacart.parquet\",\n",
    "    max_seq=CONTEXT_TOKENS,\n",
    "    downstream_task_cohort=None,\n",
    "    outcome_vars=None,\n",
    "    time_operation=lambda x: x[\"t\"],\n",
    "    seq_id_col=\"user_id\",\n",
    "    set_id_col=\"order_number\",\n",
    "    token_col=\"product_id\",\n",
    "    additional_cols=[\"t\"]\n",
    ")\n",
    "train, valid = random_split(\n",
    "    dataset=instacart,\n",
    "    lengths=[0.9, 0.1],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8627b-9871-45fb-a656-290d2e665057",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73e1bfb-2f7e-4e19-9cb6-52b7f98fc0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = load_cfg(\"./config/instacart_bert.yaml\")\n",
    "tk = Tokenizer.from_file(f\"./{cfg_dict['model']['tokenizer']}\")\n",
    "\n",
    "cfg = FMConfig(\n",
    "    vocab_size=tk.get_vocab_size(),\n",
    "    dataset=cfg_dict[\"dataset\"],\n",
    "    trainer=cfg_dict[\"trainer\"],\n",
    "    **cfg_dict[\"model\"],\n",
    ")\n",
    "model = build_model(cfg, \"FMBert\", device)\n",
    "trainer = build_trainer(cfg, model, tk, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f11ed-7965-4b64-826c-0409c88cf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "with FlopCounterMode(display=False) as flop_counter:\n",
    "    logits, h = model(\n",
    "        batch[\"input_ids\"].to(device),\n",
    "        batch[\"attention_mask\"].to(device),\n",
    "        batch[\"t\"].to(device),\n",
    "    )\n",
    "    \n",
    "total_flops = flop_counter.get_total_flops()\n",
    "print(f\"Total FLOPs: {total_flops / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total FLOPs: {total_flops / (CONTEXT_TOKENS * BATCH_SIZE) / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e5680b-8b32-43ac-abc8-9ad80cc3bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 77.12 M\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "    num_params += param.numel()\n",
    "print(f\"Total number of parameters: {num_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac2392-5909-495a-a1c7-7ec6ac206a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_time_list = []\n",
    "for _ in tqdm(range(30)):\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    t = batch[\"t\"].to(device)\n",
    "    \n",
    "    masked_input_ids, labels = random_masking(\n",
    "        input_ids.clone(), tk, 0.2\n",
    "    )\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    logits, _ = model(\n",
    "        input_ids=masked_input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        t=t,\n",
    "    )\n",
    "    loss = CrossEntropyLoss(ignore_index=-100)(\n",
    "        logits.view(-1, logits.size(-1)), labels.view(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    step_time = t1 - t0\n",
    "\n",
    "    step_time_list.append(step_time)\n",
    "    \n",
    "    del logits, _, batch\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa619e7c-3b92-4f86-a474-63344387bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean step time: {np.mean(step_time_list):.2f} sec\")\n",
    "print(f\"Std  step time: {np.std(step_time_list):.2f} sec\")\n",
    "print(f\"Mean throughput: {(CONTEXT_TOKENS / np.array(step_time_list)).mean():.2f} #tokens/sec\")\n",
    "print(f\"Std  throughput: {(CONTEXT_TOKENS / np.array(step_time_list)).std():.2f} #tokens/sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a6a49",
   "metadata": {},
   "source": [
    "#### Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f83d042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = load_cfg(\"./config/instacart_longformer.yaml\")\n",
    "tk = Tokenizer.from_file(f\"./{cfg_dict['model']['tokenizer']}\")\n",
    "\n",
    "cfg = FMConfig(\n",
    "    vocab_size=tk.get_vocab_size(),\n",
    "    dataset=cfg_dict[\"dataset\"],\n",
    "    trainer=cfg_dict[\"trainer\"],\n",
    "    **cfg_dict[\"model\"],\n",
    ")\n",
    "model = build_model(cfg, \"FMLongformer\", device)\n",
    "trainer = build_trainer(cfg, model, tk, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e1d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 1356.14 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "with FlopCounterMode(display=False) as flop_counter:\n",
    "    logits, h = model(\n",
    "        batch[\"input_ids\"].to(device),\n",
    "        batch[\"attention_mask\"].to(device),\n",
    "        batch[\"t\"].to(device),\n",
    "    )\n",
    "    \n",
    "total_flops = flop_counter.get_total_flops()\n",
    "print(f\"Total FLOPs: {total_flops / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fcf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total FLOPs: {total_flops / (CONTEXT_TOKENS * BATCH_SIZE) / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09243b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "    num_params += param.numel()\n",
    "print(f\"Total number of parameters: {num_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbde920",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_time_list = []\n",
    "for _ in tqdm(range(30)):\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    t = batch[\"t\"].to(device)\n",
    "    \n",
    "    masked_input_ids, labels = random_masking(\n",
    "        input_ids.clone(), tk, 0.2\n",
    "    )\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    logits, _ = model(\n",
    "        input_ids=masked_input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        t=t,\n",
    "    )\n",
    "    loss = CrossEntropyLoss(ignore_index=-100)(\n",
    "        logits.view(-1, logits.size(-1)), labels.view(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    step_time = t1 - t0\n",
    "\n",
    "    step_time_list.append(step_time)\n",
    "    \n",
    "    del logits, _, batch\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed3e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean step time: {np.mean(step_time_list):.2f} sec\")\n",
    "print(f\"Std  step time: {np.std(step_time_list):.2f} sec\")\n",
    "print(f\"Mean throughput: {(CONTEXT_TOKENS / np.array(step_time_list)).mean():.2f} #tokens/sec\")\n",
    "print(f\"Std  throughput: {(CONTEXT_TOKENS / np.array(step_time_list)).std():.2f} #tokens/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1cc0f-046d-4aff-9441-b88b7d47d71c",
   "metadata": {},
   "source": [
    "### base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2c059-05a3-42bd-899d-b27855e4cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "instacart = SeqSet(\n",
    "    tokenizer=tk,\n",
    "    data_root=\"./dataset/instacart/data\",\n",
    "    data_folder=\"./dataset/instacart/data/instacart.parquet\",\n",
    "    max_seq=64,\n",
    "    max_set_size=32,\n",
    "    downstream_task_cohort=None,\n",
    "    outcome_vars=None,\n",
    "    time_operation=lambda x: x[\"t\"],\n",
    "    seq_id_col=\"user_id\",\n",
    "    set_id_col=\"order_number\",\n",
    "    token_col=\"product_id\",\n",
    "    additional_cols=[\"t\"]\n",
    ")\n",
    "train, valid = random_split(\n",
    "    dataset=instacart,\n",
    "    lengths=[0.9, 0.1],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea4365-d703-47fb-97d0-774877d4d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = load_cfg(\"./config/instacart_base.yaml\")\n",
    "tk = Tokenizer.from_file(f\"./{cfg_dict['model']['tokenizer']}\")\n",
    "\n",
    "cfg = FMConfig(\n",
    "    vocab_size=tk.get_vocab_size(),\n",
    "    dataset=cfg_dict[\"dataset\"],\n",
    "    trainer=cfg_dict[\"trainer\"],\n",
    "    **cfg_dict[\"model\"],\n",
    ")\n",
    "model = build_model(cfg, \"FMBase\", device)\n",
    "trainer = build_trainer(cfg, model, tk, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb526d54-7903-4b23-8fbb-7f80906263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb252a6e-c8f5-4c75-a155-e94165e53cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with FlopCounterMode(display=False) as flop_counter:\n",
    "    logits, h = model(\n",
    "        batch[\"input_ids\"].to(device),\n",
    "        batch[\"attention_mask\"].to(device),\n",
    "        batch[\"set_attention_mask\"].to(model.device),\n",
    "        batch[\"t\"].to(device),\n",
    "    )\n",
    "    \n",
    "total_flops = flop_counter.get_total_flops()\n",
    "print(f\"Total FLOPs: {total_flops / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total FLOPs: {total_flops / (CONTEXT_TOKENS * BATCH_SIZE) / 1e9:.2f} GFLOPs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99701482-228f-415b-a107-71587a20899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "    num_params += param.numel()\n",
    "print(f\"Total number of parameters: {num_params / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9b98d-cbac-4e44-971c-d685373683dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_time_list = []\n",
    "for _ in tqdm(range(30)):\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    set_attention_mask = batch[\"set_attention_mask\"].to(device)\n",
    "    t = batch[\"t\"].to(device)\n",
    "    \n",
    "    masked_input_ids, labels = random_masking(\n",
    "        input_ids.clone(), tk, 0.2\n",
    "    )\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.time()\n",
    "    logits, _ = model(\n",
    "        input_ids=masked_input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        set_attention_mask=set_attention_mask,\n",
    "        t=t,\n",
    "    )\n",
    "    loss = CrossEntropyLoss(ignore_index=-100)(\n",
    "        logits.view(-1, logits.size(-1)), labels.view(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "    torch.cuda.synchronize()\n",
    "    t1 = time.time()\n",
    "    step_time = t1 - t0\n",
    "\n",
    "    step_time_list.append(step_time)\n",
    "    \n",
    "    del logits, _, batch\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be7cae-c275-4a2b-9485-6ed0a253ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean step time: {np.mean(step_time_list):.2f} sec\")\n",
    "print(f\"Std  step time: {np.std(step_time_list):.2f} sec\")\n",
    "print(f\"Mean throughput: {(CONTEXT_TOKENS / np.array(step_time_list)).mean():.2f} #tokens/sec\")\n",
    "print(f\"Std  throughput: {(CONTEXT_TOKENS / np.array(step_time_list)).std():.2f} #tokens/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c6f91-591b-4fef-a4b1-354449e36121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
