{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c3cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from src.layer import TransformerBlock, HierarchicalTransformerBlock\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124780de",
   "metadata": {},
   "outputs": [],
   "source": [
    "768 * 4 * 2/3\n",
    "# d_ff = d_model * 4 * 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "768 / 8\n",
    "# d_k = d_model / h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c61291",
   "metadata": {},
   "source": [
    "#### test transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15807b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerBlock(\n",
    "    d_model=768,\n",
    "    d_ff=2048,\n",
    "    h=12,\n",
    "    dropout=0,\n",
    "    norm_type=\"layer\",\n",
    "    ffn_type=\"swiglu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6be3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.to(\"cuda\")\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 128, 512).to(\"cuda\")\n",
    "masks = torch.ones(2, 128).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60add3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder(inputs, masks).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7eea7e",
   "metadata": {},
   "source": [
    "#### test hierarchical transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f7e6caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_block = HierarchicalTransformerBlock(\n",
    "    d_model=512,\n",
    "    d_ff=1024,\n",
    "    h=4,\n",
    "    dropout=0,\n",
    "    norm_type=\"layer\",\n",
    "    ffn_type=\"swiglu\",\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8f37e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.250048"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(hat_block) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "763948be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.74"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2e4 * 512 + 5.25e6 * 6) / 1e6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c77a92b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_hidden_state = torch.randn(32, 32, 128, 768).cuda()\n",
    "token_mask = torch.rand(32, 32, 128).bernoulli().cuda()\n",
    "seg_mask = torch.rand(32, 32).bernoulli().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa07351b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 128, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_block(seg_hidden_state, token_mask, seg_mask).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a84a1",
   "metadata": {},
   "source": [
    "#### RoPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa367332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.layer import RoPE\n",
    "\n",
    "rope = RoPE(d=256)\n",
    "x = torch.randn(2, 12, 32, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f5b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rope(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad83ab07",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b0d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fm import FMConfig, FMBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69381ef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "d_model must be divisible by h",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m cfg = FMConfig(d_model=\u001b[32m512\u001b[39m, **{\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1e-5\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m8\u001b[39m})\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mFMBase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m cfg.to_diff_dict()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\ehr-fm\\src\\fm.py:86\u001b[39m, in \u001b[36mFMBase.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(config)\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.embeddings = FMEmbeddings(config)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28mself\u001b[39m.transformer_encoder = \u001b[43mFMTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.lm_head = nn.Linear(config.hidden_size, config.vocab_size)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.weight_tying:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:4\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\ehr-fm\\src\\layers\\hierarchical.py:19\u001b[39m, in \u001b[36mHierarchicalTransformerBlock.__init__\u001b[39m\u001b[34m(self, d_model, d_ff, h, dropout, norm_type, ffn_type, attn_backend)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# segment-wise encoder\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mself\u001b[39m.swe = \u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_backend\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# cross-segment encoder\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.cse = TransformerBlock(\n\u001b[32m     24\u001b[39m     d_model, d_ff, h, \u001b[38;5;28;01mTrue\u001b[39;00m, dropout, norm_type, ffn_type, attn_backend\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\ehr-fm\\src\\layers\\transformer.py:25\u001b[39m, in \u001b[36mTransformerBlock.__init__\u001b[39m\u001b[34m(self, d_model, d_ff, h, with_rope, dropout, norm_type, ffn_type, attn_backend)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03md_ff = 4 * d_model\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03mbut *GLU typically scale down by 2/3 to previous parameter size\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28mself\u001b[39m.self_attn_block = \u001b[43mMultiHeadAttentionBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_rope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_backend\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mself\u001b[39m.ffn_block = (\n\u001b[32m     29\u001b[39m     FFNSwiGLUBlock(d_model, d_ff)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ffn_type == \u001b[33m\"\u001b[39m\u001b[33mswiglu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m FFNLUBlock(d_model, d_ff, ffn_type)\n\u001b[32m     32\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.residual_connection = ResidualConnection(d_model, dropout, norm_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\ehr-fm\\src\\layers\\attention.py:17\u001b[39m, in \u001b[36mMultiHeadAttentionBlock.__init__\u001b[39m\u001b[34m(self, d_model, h, with_rope, attn_backend)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.h = h\n\u001b[32m     15\u001b[39m \u001b[38;5;28mself\u001b[39m.with_rope = with_rope\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m d_model % h == \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33md_model must be divisible by h\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.d_k = d_model // h  \u001b[38;5;66;03m# dimension of each head\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.w_q = nn.Linear(d_model, d_model, bias=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAssertionError\u001b[39m: d_model must be divisible by h"
     ]
    }
   ],
   "source": [
    "cfg = FMConfig(d_model=512, n_heads=8, d_ff=1024, **{\"lr\": 1e-5, \"batch_size\": 8})\n",
    "model = FMBase(cfg).to(\"cuda\")\n",
    "cfg.to_diff_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b37d2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59033b",
   "metadata": {},
   "source": [
    "#### simcse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7409459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loss import SimCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4511a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e369c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simcse = SimCSE(model, temperature=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
